{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7117585,"sourceType":"datasetVersion","datasetId":4104876},{"sourceId":7119043,"sourceType":"datasetVersion","datasetId":4105888},{"sourceId":7157921,"sourceType":"datasetVersion","datasetId":4133944}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ar = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_ARMSTRONG (AUT)_3987.csv\")\ncape = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_CAPE DYER_1739.csv\")\ncold = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_CAPE PARRY A_1633.csv\")\ncomox = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_COLD LAKE A_2832.csv\")\ngr = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_COMOX A_155.csv\")\nha =pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_GREENWOOD A_6354.csv\")\nho = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_HAINES JUNCTION_1556.csv\")\npi = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_HOPEDALE (AUT)_6781.csv\")\ntr = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_PILOT MOUND (AUT)_3649.csv\")\nt = pd.read_csv(\"/kaggle/input/new-weather-extreme/Into-the-weather-main/data/Daily_TRENTON A_5126.csv\")\n\n\nr = pd.concat([ar, cape], axis=0)\nr1 = pd.concat([r, cold], axis=0)\nr2 = pd.concat([r1, comox], axis=0)\nr3 = pd.concat([r2, gr], axis=0)\nr4 = pd.concat([r3, ha], axis=0)\nr5 = pd.concat([r4, ho], axis=0)\nr6 = pd.concat([r5, pi], axis=0)\nr7 = pd.concat([r6, tr], axis=0)\ndata = pd.concat([r7, t], axis=0)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[[\"Station Name\",\"Year\",\"Month\",\"Day\",\"Mean Temp (°C)\",\"Heat Deg Days (°C)\",\"Cool Deg Days (°C)\",\"Total Rain (mm)\",\"Total Snow (cm)\",\"Total Precip (mm)\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Station Name'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[data['Station Name'] == 'CAPE DYER']\n\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \ndata['Station Name']= label_encoder.fit_transform(data['Station Name']) \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.interpolate(limit_direction='both')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Total Rain (mm)'].fillna(int(data['Total Rain (mm)'].mean()), inplace=True) \ndata['Total Snow (cm)'].fillna(int(data['Total Snow (cm)'].mean()), inplace=True) \ndata['Total Precip (mm)'].fillna(int(data['Total Precip (mm)'].mean()), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.rename(columns={'Mean Temp (°C)': 'Temperature', 'Total Rain (mm)': 'Rainfall','Total Snow (cm)':'Snowfall','Total Precip (mm)':'Precipitation'}, inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[[\"Station Name\",\"Year\",\"Month\",\"Day\",\"Temperature\",\"Rainfall\",\"Snowfall\",\"Cool Deg Days (°C)\",\"Precipitation\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Extreme_Weather_Condition'] = 'Unknown'\n\nfor index, row in data.iterrows():\n    if row['Temperature'] <= -30:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Extreme Cold'\n    elif row['Temperature'] <= 0 and row['Precipitation'] > 0:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Freezing Rain'\n    elif row['Temperature'] >= 35:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Heat Warning'\n    elif row['Precipitation'] >= 30:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Heavy Rainfall'\n    elif row['Snowfall'] >= 10:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Heavy Snowfall'\n    elif row['Rainfall'] >= 10 or row['Snowfall'] >= 10 or row['Cool Deg Days (°C)'] >= 40:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Snow Storm'\n    else:\n        data.at[index, 'Extreme_Weather_Condition'] = 'Normal'\n\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Extreme_Weather_Condition'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Extreme_Weather_Condition']= label_encoder.fit_transform(data['Extreme_Weather_Condition']) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Combine 'Year', 'Month', and 'Day' columns into a new 'Date' column\ndata['Date'] = pd.to_datetime(data[['Year', 'Month', 'Day']])\n\ndata = data.sort_values(by='Date', ascending=True)\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\n\n\n# Prepare data for LSTM\nX = data[['Year', 'Month', 'Day', 'Temperature', 'Rainfall', 'Snowfall', 'Cool Deg Days (°C)', 'Precipitation']].values\ny = data['Extreme_Weather_Condition'].values\n\n\n# Normalize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25,shuffle = False)\n\n# Reshape data for LSTM input (samples, timesteps, features)\nX_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\nX_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n\nmodel = Sequential()\nmodel.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Dropout(0.3))  # Reduced dropout for better information flow\nmodel.add(LSTM(units=64, return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(units=32))  # Removed return_sequences=True for final layer\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units=7, activation='softmax'))\nmodel.summary()\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\npredict = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to forecast extreme weather condition for multiple future dates\ndef forecast_multiple_days(model, scaler, initial_date, num_days):\n    # Create lists to store forecasted dates and extreme weather conditions\n    forecast_dates = []\n    forecast_weather = []\n\n    # Start forecasting from the initial_date for the next 'num_days'\n    current_date = initial_date\n    \n    for day in range(num_days):\n        # Prepare the input data for the current date\n        future_data = [current_date.year, current_date.month, current_date.day, 0, 0, 0, 0, 0]  # Replace with appropriate values\n        \n        # Scale the future date data using the same scaler used for training data\n        future_data_scaled = scaler.transform([future_data])\n        \n        # Reshape the data for LSTM input (samples, timesteps, features)\n        future_data_reshaped = np.reshape(future_data_scaled, (1, 1, len(future_data)))\n        \n        # Predict the extreme weather condition for the future date\n        prediction = model.predict(future_data_reshaped)\n        predicted_label = np.argmax(prediction)\n        \n        # Store the forecasted date and extreme weather condition\n        forecast_dates.append(current_date)\n        forecast_weather.append(predicted_label)\n        \n        # Update current_date to the next day for the next iteration\n        current_date += pd.Timedelta(days=1)\n    \n    # Create a DataFrame from the forecasted data\n    forecast_data = pd.DataFrame({'Date': forecast_dates, 'Forecasted_Weather': forecast_weather})\n    \n    return forecast_data\n\n# Example: Forecast the next 60 days starting from a specific date\nstart_date = pd.to_datetime('2023-12-15')  # Replace with your desired start date\nforecast_result = forecast_multiple_days(model, scaler, start_date, num_days=25)\nprint(forecast_result)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to map numerical predictions to labels/categories\ndef map_to_labels(predictions):\n    # Define your mapping based on the numerical values predicted by the model\n    # Replace this mapping with your actual mapping logic based on your model's output\n    labels = ['Extreme Cold', 'Freezing Rain', 'Heat Warning', 'Rainfall', 'Snowfall', 'Snow Storm', 'Normal']\n    return [labels[pred] for pred in predictions]\n\n# Example usage:\npredicted_weather_labels = map_to_labels(forecast_result['Forecasted_Weather'])\n\n# Combine the forecasted dates with the corresponding weather condition labels\nforecast_result['Forecasted_Weather_Labels'] = predicted_weather_labels\n\n# Display or use the DataFrame containing forecasted dates and labels for the next 60 days\nprint(forecast_result)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving Forecasted File to csv\nforecast_result.to_csv('ARMSTRONG BC.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}